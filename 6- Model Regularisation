# -*- coding: utf-8 -*-
"""
Created on Wed Apr 30 21:43:38 2025

@author: Lenovo
"""

import pandas as pd
import numpy as np

def nullCount(data):
    
    null_count = data.isnull().sum()
    null_percentage = (data.isnull().sum() / len(data)) * 100

    # Combine into a single DataFrame
    null_summary = pd.DataFrame({
        'Null_Count': null_count,
        'Null_Percentage': null_percentage
    })
    
    return null_summary

def imputeMissVal(data, null_count, numeric_cols, string_cols):    # numericalVar: median, cateoricalVar: mode
    
    for index, rows in null_count.iterrows():
        
        if rows[0] < 1:    # i.e. nan values is = 0 (treating float value)
            continue
        
        if index in numeric_cols:
            data[index].fillna(data[index].median(), inplace=True) 
            
        elif index in string_cols:
            data[index].fillna(data[index].mode(), inplace=True) 

# reading data    
data = pd.read_csv("auto-mpg.csv")

# pop() carname
data.drop('car name', axis=1, inplace=True)

# replace special characters to 'nan' and convert in float
data['horsepower'] = pd.to_numeric(data['horsepower'], errors='coerce')

# checking null data
null_count = nullCount(data)

numeric_cols = data.select_dtypes(exclude=['object']).columns.tolist()
string_cols = data.select_dtypes(include=['object']).columns.tolist()

# imputing missing values
imputeMissVal(data, null_count, numeric_cols, string_cols)

# One-hot encode 'origin' and drop the first category
origin_dummies = pd.get_dummies(data['origin'], prefix='origin', drop_first=True)

# Concatenate with original data after dropping 'origin'
data = pd.concat([data.drop('origin', axis=1), origin_dummies], axis=1)

# Train Test Split
from sklearn.model_selection import train_test_split
df_train, df_test = train_test_split(data, train_size = 0.8, test_size = 0.2, random_state = 100)

y_train = df_train.pop('mpg') #labels in training data
x_train = df_train # features in training data

y_test = df_test.pop('mpg') #lables in test data
x_test = df_test # features in test data

# data scaling
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

# Model Training
from sklearn.linear_model import LinearRegression, Ridge, Lasso

# Linear Regression
lr_model = LinearRegression()
lr_model.fit(x_train, y_train) # training

y_train_lr_pred = lr_model.predict(x_train)
y_test_lr_pred = lr_model.predict(x_test)

# Lasso Regression
lasso_model = Lasso(alpha=0.1) #alpha` must be a non-negative float i.e. in `[0, inf)
lasso_model.fit(x_train,y_train)

y_train_lasso_pred = lasso_model.predict(x_train)
y_test_lasso_pred = lasso_model.predict(x_test)

# Ridge Regression
ridge_model = Ridge(alpha=0.1) #alpha` must be a non-negative float i.e. in `[0, inf)
ridge_model.fit(x_train,y_train)

y_train_ridge_pred = ridge_model.predict(x_train)
y_test_ridge_pred = ridge_model.predict(x_test)

# Model Evaluation
from sklearn.metrics import r2_score,mean_absolute_error,mean_absolute_percentage_error

r2_score_lr_train = r2_score(y_train, y_train_lr_pred)
r2_score_lr_test = r2_score(y_test, y_test_lr_pred)

r2_score_lasso_train = r2_score(y_train, y_train_lasso_pred)
r2_score_lasso_test = r2_score(y_test, y_test_lasso_pred)

r2_score_ridge_train = r2_score(y_train, y_train_ridge_pred)
r2_score_ridge_test = r2_score(y_test, y_test_ridge_pred)


# Regularisation can be used for logistic regression 
#from sklearn.linear_model import LogisticRegression

# L2 regularization (default)
#model = LogisticRegression(penalty='l2', C=1.0)

# L1 regularization
#model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)

# ElasticNet
#model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0)
